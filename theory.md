# 蒙特卡罗方法采样算法

&emsp;&emsp;蒙特卡罗方法(`Monte Carlo Simulation`)是一种随机模拟(或者统计模拟)方法。

&emsp;&emsp;给定统计样本集，如何估计产生这个样本集的随机变量概率密度函数,是我们比较熟悉的概率密度估计问题。
求解概率密度估计问题的常用方法是最大似然估计、最大后验估计等。但是,我们思考概率密度估计问题的逆问题:给定一个概率分布`p(x)`，如何让计算机生成满足这个概率分布的样本。
这个问题就是统计模拟中研究的重要问题–采样(`Sampling`)。本文将重点介绍其中两种重要的采样算法：`MCMC(Markov Chain Monte Carlo)`算法和`Gibbs Sampling`算法。

## Sampling

&emsp;&emsp;一般而言均匀分布`Uniform(0,1)`的样本是相对容易生成的。 通过线性同余发生器可以生成伪随机数，我们用确定性算法生成`[0,1]`之间的伪随机数序列后，
这些序列的各种统计指标和均匀分布`Uniform(0,1)`的理论计算结果非常接近。这样的伪随机序列就有比较好的统计性质，可以被当成真实的随机数使用。线性同余随机数生成器如下:

$$x_{n+1}=(ax_n+c)~\textrm{mod}~m$$

&emsp;&emsp;式中`aa`，`cc`，`mm`是数学推导出的合适的常数。这种算法产生的下一个随机数完全依赖当前的随机数，当随机数序列足够大的时候，随机数会出现重复子序列的情况。
当然，也有很多更加先进的随机数产生算法出现，比如`numpy`用的是 `Mersenne Twister` 等。根据上面的算法现在我们有了均匀分布的随机数，但是如何产生满足其他分布下的随机数呢？

&emsp;&emsp;首先我们来看一个简单的例子，假设我们想对下面的二项分布进行采样:

$$P(X=0)=0.5 ~,~ P(X=1)=0.5$$

&emsp;&emsp;我们如何采样得到$X$的值。我们会很毫不费力地想到“抛硬币”，如果硬币正面朝上，则$X=1$，否则，$X=0$。那计算机怎么做，使用随机数生成器生成0到1之间的随机数$r$，
如果$r<0.5$，则$X=1$，否则，$X=0$。当分布是多项式分布时:

$$P(X=i)=1/6 ~,~ i\in{1,2,...,6}$$

&emsp;&emsp;这也很简单，让算机生成0到1之间的随机数$r$，把0到1等分成6个子区间，$r$落在哪个区间，$X$就取值为那个区间的编号。我们再考虑更复杂的情况，假设分布是多元随机变量分布:

$$P(X_1,X_2,...,X_n)$$
